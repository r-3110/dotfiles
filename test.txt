To find out what the agent did, I use an observability tool. There are many options, I picked the tool MLflow. The screenshot in the upper left corner shows what happened. It is hard to read, because the output is very verbose. This is currently an issue with many observability tools and I’m going to talk about this later. To make the essential part easier to read I’ve zoomed in. The red and black rectangles highlight the key information.

The agent identified that the weather tool needs to be invoked. However, the invocation failed since the tool requires a property ‘start_date’. So, the agent called the same tool a second time, this time with the current date as start date. The ability of agents to auto correct themselves is powerful. But in this case the Large Language Model was invoked twice. This leads to higher costs primarily caused by the GPU resources. This behavior also leads to longer response times, especially for larger models. Via an extra instruction this issue could be avoided.
